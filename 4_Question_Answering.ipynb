{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1RcZQEh40Ypvu0m9pdfvUV78_2Nes1pSm",
   "authorship_tag": "ABX9TyPRcM9BSe5Y96zkU9XDKmts"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J7NHXdSHJJDi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749484578434,
     "user_tz": -120,
     "elapsed": 7874,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question Answering: Chat Bot\n",
    "**Utilisation du modèle T5 de google**\n",
    "\n",
    "- Le jeu de données contient 200 avis, questions et réponses collectés auprès de visiteurs à Marrakech"
   ],
   "metadata": {
    "id": "OFdP3JC0bCG-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U transformers"
   ],
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6te5nDdOs_2f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749489556742,
     "user_tz": -120,
     "elapsed": 4327,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "e2d6cf97-5335-4f1b-c273-f14d090b2582"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Installation des librairies libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ],
   "metadata": {
    "id": "eL770lplbSHs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749490752227,
     "user_tz": -120,
     "elapsed": 14371,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Vérification de la disponibilité du GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kdl66j5Zkpf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749490754921,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "f3a429be-5643-4917-cb9a-fc288338c726"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install datasets"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3WZaeInoZk2I",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749490765169,
     "user_tz": -120,
     "elapsed": 6066,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "14a48b10-87c3-4ab8-ee8a-35149be7b31e"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversion au format json"
   ],
   "metadata": {
    "id": "B5_2PkAtbhJF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# chargement de la data set contenant les questions et réponses\n",
    "file_path = \"QA.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "if 'Question' not in df.columns or 'Answer' not in df.columns:\n",
    "    raise ValueError(\"The Excel file must have 'Question' and 'Answer' columns.\")\n",
    "\n",
    "# Conversion au format json\n",
    "data = []\n",
    "for _, row in df.iterrows():\n",
    "    data.append({\n",
    "        \"instruction\": row['Question'],\n",
    "        \"input\": row['Review'],\n",
    "        \"output\": row['Answer']\n",
    "    })\n",
    "\n",
    "# enrégistrement au format json\n",
    "output_path = \"qa_dataset.json\"\n",
    "with open(output_path, \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print(f\"Data saved to {output_path}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbnJi3RpZlCK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749490826178,
     "user_tz": -120,
     "elapsed": 453,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "cbdcd40e-da14-48d9-b1cf-69826011ed26"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data saved to qa_dataset.json\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "id": "2qSOvUj783rZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749493727572,
     "user_tz": -120,
     "elapsed": 124,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "f636bd66-3f01-4806-caab-49a818e991c4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    }
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Review  \\\n",
       "0  You can’t go to Marrakech without going to Jem...   \n",
       "1  You can’t go to Marrakech without going to Jem...   \n",
       "2  You can’t go to Marrakech without going to Jem...   \n",
       "3  Haggle Haggle Haggle, that's what you must do ...   \n",
       "4  Haggle Haggle Haggle, that's what you must do ...   \n",
       "\n",
       "                                            Question  \\\n",
       "0    Can you describe the ambiance of Jemaa el-Fnaa?   \n",
       "1  How would you characterize the atmosphere of J...   \n",
       "2  What sets the experience of visiting Jemaa el-...   \n",
       "3  What is the key approach to shopping in this a...   \n",
       "4  How would you describe the pricing culture in ...   \n",
       "\n",
       "                                              Answer  \n",
       "0  It’s crazy and wild and loud and busy - it’s a...  \n",
       "1  It’s crazy and wild and loud and busy - it’s a...  \n",
       "2  It’s hard to imagine until you are actually th...  \n",
       "3  Haggle Haggle Haggle, that's what you must do ...  \n",
       "4  nothing is expensive.. just make sure you neve...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-7faa2671-cd10-49a5-9461-3ebb5fa4bf53\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can’t go to Marrakech without going to Jem...</td>\n",
       "      <td>Can you describe the ambiance of Jemaa el-Fnaa?</td>\n",
       "      <td>It’s crazy and wild and loud and busy - it’s a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can’t go to Marrakech without going to Jem...</td>\n",
       "      <td>How would you characterize the atmosphere of J...</td>\n",
       "      <td>It’s crazy and wild and loud and busy - it’s a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You can’t go to Marrakech without going to Jem...</td>\n",
       "      <td>What sets the experience of visiting Jemaa el-...</td>\n",
       "      <td>It’s hard to imagine until you are actually th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haggle Haggle Haggle, that's what you must do ...</td>\n",
       "      <td>What is the key approach to shopping in this a...</td>\n",
       "      <td>Haggle Haggle Haggle, that's what you must do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haggle Haggle Haggle, that's what you must do ...</td>\n",
       "      <td>How would you describe the pricing culture in ...</td>\n",
       "      <td>nothing is expensive.. just make sure you neve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7faa2671-cd10-49a5-9461-3ebb5fa4bf53')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7faa2671-cd10-49a5-9461-3ebb5fa4bf53 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7faa2671-cd10-49a5-9461-3ebb5fa4bf53');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-f541135b-2835-42f5-b926-28e8a4947b00\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f541135b-2835-42f5-b926-28e8a4947b00')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-f541135b-2835-42f5-b926-28e8a4947b00 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df",
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 201,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"The Jemaa el Fna should be the first place you visit when coming to Marrakech. This square gather all the possible attractions you could imagine to find in Morocco. Just to name few the food, here you will not only find restaurants but also street food stands where you can try the local cuisine and also international dishes. The souk, with wonderful things to a very affordable price. Get henna on the square or watch the dancers and story tellers performing in front of a crowed of locals and foreigners.\\nJust one piece of advice, keep your belongins well hidden in a place no one can have easy access. In general Morocco is a safe place but sometimes when people are so immerse in the magic of the square they give chance to unscrupulous people to take advantage of you.\\nOther than that you are safe.\",\n          \"This place become lively after sunset with numerous hawkers, snake charmers and food stalls. However, beware of pickpockets and hawkers who lure you into buying things. Its a good place to walk around and get the essence of the city. But not an ideal location to shop as it can be overwhelming and highly priced compared to the souks inside.\",\n          \"It's a major world attraction and worth seeing. We didn't end up buying anything or eating there since everything around the square was available elsewhere, cheaper and for less hassle. Still, fun to join the rank of a thousand years' worth of tourists visiting this place.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"What are the distinguishing features or attractions of Marrakech?\",\n          \"What is recommended for experiencing the culture and art in Marrakech?\",\n          \"What are some recommended accommodations in Marrakech?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 69,\n        \"samples\": [\n          \"Where you can enjoy and buy new and wonderful things like a gift for you and for your lovers.\",\n          \"It\\u2019s crazy and wild and loud and busy - it\\u2019s a cultural assault of smells, sounds, and people.\",\n          \"Motorcycles, bicycles, donkey carts, pedestrians, cats, children, food vendors ... you name it, this place has it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 41
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Lire le fichier JSON manuellement pour éviter les message d'erreus\n",
    "with open(\"qa_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convertir la liste en Dataset Hugging Face\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "\n",
    "# Split train/val\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_data = train_test_split['train']\n",
    "val_data = train_test_split['test']\n",
    "\n",
    "# train/test(val)\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_data = train_test_split['train']\n",
    "val_data = train_test_split['test']\n",
    "\n",
    "# clé d'authentification permettant le chargement du modèle de google sur hugging face\n",
    "auth_token = \"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\"\n",
    "model_name = \"google/flan-t5-small\" # prendre le grand model si GPU disponible\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, use_auth_token=auth_token)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, use_auth_token=auth_token)\n",
    "\n",
    "# Tokenize Data\n",
    "def preprocess_function(examples):\n",
    "    inputs = [f\"question: {q} answer:\" for q, r in zip(examples[\"instruction\"], examples[\"input\"])] # les questions et le context\n",
    "    targets = examples[\"output\"] # les réponses\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\") # récupération des ids, les mask d'attention\n",
    "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"] # récupération des ids des réponses\n",
    "    return model_inputs\n",
    "\n",
    "train_data = train_data.map(preprocess_function, batched=True)\n",
    "val_data = val_data.map(preprocess_function, batched=True)\n",
    "\n",
    "# Accuracy, precision, F-measure\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=1).numpy()\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1}\n",
    "\n",
    "# Definition des arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"fine_tuned_t5\",\n",
    "    save_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551,
     "referenced_widgets": [
      "e25803d31aeb4408bdcadf66863fc0f4",
      "239a71becf1f47b081eb24b9f93ace23",
      "7eac10182d204a3c8ef1c25a2cedffc8",
      "3d0c20c8cd214385b2231dffb57718d0",
      "4304c8f48d714c9aabfa0933db0652a6",
      "0dd5e1af7870427ab94c438496e8b93d",
      "6f8fde72ce864d838672b2d7a3657568",
      "9101faa1174b48168f0b1db6ee8055bb",
      "37143fbcadca4e189ea727c686fc4483",
      "6d08fee87b074f1dac5689f5e630f51f",
      "dfa7d472ce30414ab4a964af497fa0ce",
      "b8752dde720a46189201a446dcffb128",
      "cb236999e39e4146854efb9bb26724d3",
      "fc6f8576930748dc9d5bce31500a2195",
      "abea43da1b1c4c64aa7fa85649e9136c",
      "97ade5e029674bb2aaabbbb902ca081e",
      "b5ed69a571ac42a3a5b4ae572197473f",
      "85011df0161549e4ad86916a13450f31",
      "385503c0c5da4d3f8b5ab10f63d09def",
      "0ce59fbc91d64658a1136e6faec40909",
      "34f076ccdece420ea427875dbc200dce",
      "9037a4aecdb04a23aa89d9d2261a530b",
      "bfeb7f5096a241fea4e42ee9bd0e265c",
      "8b81b03941dc465ca171db84724820cb",
      "86ba8b55c9804ac39a8ef2046029ef81",
      "498a88f9dbf94c6583b55cc7a4dd422f",
      "70625822daf542da9123c0148392ca3b",
      "4401a246b1d84a698599c1b78418b892",
      "756cb48e4351437eb4ad89ccae748eb1",
      "ab505b33a2424ba8840a116028c285be",
      "92fe55998f254012a899be3fb6105dc1",
      "f944c3f980254726819fb350147b0737",
      "19d546c295ec4211839ee6154fa4075f",
      "a48caeaa079d4e72bcdaa8c3e3b40e87",
      "106de2924f0d4d87ad7874b7484964b3",
      "fd1ae32575a64e9a95e140dbda95511e",
      "dc81aca1f96c42e295cab946bcac5f16",
      "8cc6ca410dfb474ea2b92b53aa638104",
      "395942ad2cbe45c08661d79b23840637",
      "3cc706e5cae24a4a97bef54df79193d4",
      "e10d084a060d491c850f766f358adc8b",
      "5dbc47b0e0794d8289c17d78ed3eba24",
      "60932036b3a04a3b8454d38f57dd0116",
      "9d74e276cbfd49f58cffdba790e85206",
      "74efa4a7b2854b44b29baa779dbf76a3",
      "cf0cc59bfd3c49fd905a3c1cef6afe70",
      "60bfc26924ef4bcbaac2f0fcb1c05c12",
      "65845d4f2b1c43c1ad27913df64a3d74",
      "d4ae753ac8c843fca1a65c1653b4a9c6",
      "9363083f8c2e43cc9483decde2099a0c",
      "832eaaffd6db465d84880eb4a3689833",
      "a1767230000c46b2ad487f7f92bf432d",
      "41031d69ccb44d248425cdc1dfcc6306",
      "6158ba64df8943e5ab772059690568f8",
      "00c87a4d70d34d6ab253777c54f4c84a",
      "558244c5fdd142d095c0c2f57eac74ce",
      "627ecf2192de4fee951b6a6f0c4df11e",
      "f6831ffacade42399eea4106609cef8d",
      "6505c325d7a64337abcc5ae144a433bd",
      "9559fcc121c748a78079e03311fd89f3",
      "dfc09d6e509c4f67a88dd1d333b248ac",
      "b184fc50c2094388be5b6246486e9b2c",
      "22d808e8c04f4ad092350776c99da6d4",
      "94789e4497304782b35016ae782218c5",
      "5d475da06f6e46d09c2aaefe99c4d5ce",
      "5d236f623d8a4e6094c2a26350986d8e",
      "85563dcb20e344309573d04f9208b916",
      "2412b5450927469a88bb55f8a70a31c3",
      "0eb05474eb914cddb52c26cc4101117e",
      "6b27f13f6c9949fe936d1f8f1128f8cc",
      "780989ec3e5c4f91b4a84ceba18262e2",
      "cf3467a5386f4180b7a0a44205941d8c",
      "732349cdc3574368909b28684430e726",
      "e46befb0bdd94400a27912bb9c5c2314",
      "98756355552c42e186bd455c007992a6",
      "3fa538113fb840f48c0c208965fab869",
      "2cf0cf716c094988b1e0f69c0406288e",
      "81c5910d81014829a412a37c0982cf53",
      "ca9e1956cb984430bbb7bb7bd0084853",
      "19d5aa1949c84bfaa0b4d87ff97907d8",
      "745ecc14e1ab40409a8ff43ba5842e79",
      "9b202c643e2041bfa8855d707378d60d",
      "afed1c4471c94019b6c614c4cb2b32d7",
      "6d558030d9844c89ac6d47a805044038",
      "709c314e86b14f8e815d71c812b3f542",
      "cd0fd73398f9454e8c88a1d04de87df5",
      "026e34a8d31441a6b299adbe0475810d",
      "adcf7f253562457498a5e23f739eae5b",
      "e70916499ea746858f46875abd1ab9e9",
      "354fdaa3f6f1417c83483481683e048f",
      "d566e22e3bbf44ed9068009cbb4c5ba0",
      "71e261842f4e4ac1bf085b6b70965e65",
      "ca7ad89d4fe24175896680d81b7fdb0a",
      "cca8a904ded048f196d411967e68fdd9",
      "c57e9553533b493c926ba7058d0a0c24",
      "fb8da1f4867b40ca913d1af7782baac9",
      "ab9e70c2c3fc457ababc58d43c0a64e6",
      "3cbf84ea49a64ab699b80f842fda241c",
      "7bba1b35110b425a93e4621d01cd5a8b"
     ]
    },
    "id": "PGr2lmf8Zlh8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749490881014,
     "user_tz": -120,
     "elapsed": 37148,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "d82dafcb-053d-4729-ca8a-1079421c8828"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:4191: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e25803d31aeb4408bdcadf66863fc0f4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8752dde720a46189201a446dcffb128"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfeb7f5096a241fea4e42ee9bd0e265c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1864: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a48caeaa079d4e72bcdaa8c3e3b40e87"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74efa4a7b2854b44b29baa779dbf76a3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "558244c5fdd142d095c0c2f57eac74ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85563dcb20e344309573d04f9208b916"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81c5910d81014829a412a37c0982cf53"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e70916499ea746858f46875abd1ab9e9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-9-c5410d101d37>:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entrainement du model"
   ],
   "metadata": {
    "id": "QOPeNhMAiHIE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# suppression de wandb pour éviter les messages introduisnt l'achat du GPU\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import wandb\n",
    "wandb.init(mode=\"disabled\")\n",
    "# Train the Model\n",
    "trainer.train()\n",
    "\n",
    "# Save the Fine-Tuned Model\n",
    "trainer.save_model(\"fine_tuned_t5\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_t5\")\n",
    "print(\"Model saved to fine_tuned_t5/\")"
   ],
   "metadata": {
    "id": "0d0PNMmsJNcS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749492343356,
     "user_tz": -120,
     "elapsed": 1454161,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "ff53032f-d466-4da1-f308-f9b76632ebde"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 23:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>21.896600</td>\n",
       "      <td>12.175153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model saved to fine_tuned_t5/\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Chargement du fine-tuned model et le tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"fine_tuned_t5\") # model de google\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"fine_tuned_t5\")\n",
    "\n",
    "# Test tu tokenizer\n",
    "input_text = \"What can I visit in Morocco ?\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "print(\"Tokenized Input:\", input_ids)\n",
    "\n",
    "# Generate an answer using the fine-tuned model\n",
    "output_ids = model.generate(input_ids)\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"Generated Answer:\", output_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeUElxQGh5j-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749492406612,
     "user_tz": -120,
     "elapsed": 742,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "d7dbec5c-d73e-4ffe-912f-d453b6fc9b55"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tokenized Input: tensor([[  363,    54,    27,   719,    16, 25559,     3,    58,     1]])\n",
      "Generated Answer: Morocco\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# paramétrage du type de réponses\n",
    "def generate_answer(question, model, tokenizer, max_length=256, min_length=50):\n",
    "    # input (questions)\n",
    "    input_text = f\"question: {question} answer:\"\n",
    "    # Tokenize input\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    # Generate l' output avec des séquences longues\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=128,   # permet au chat de générer plus de token (mots)\n",
    "        min_length=64,\n",
    "        num_beams=5,\n",
    "        do_sample=True,\n",
    "        temperature=0.3,   # paramètre qui permet de gérer l'allucination.\n",
    "        top_p=1.,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "\n",
    "    # Decode l'output\n",
    "    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return answer\n"
   ],
   "metadata": {
    "id": "Jqj2WioSh6Ip",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749492933312,
     "user_tz": -120,
     "elapsed": 7,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"What can I visit in Marrakech?\"\n",
    "answer = generate_answer(question, model, tokenizer)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IC8oWuf9h6Tc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749492973436,
     "user_tz": -120,
     "elapsed": 3886,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "62c86fbc-a335-4d22-ab06-31183ef6f47c"
   },
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Question: What can I visit in Marrakech?\n",
      "Answer: Mozambique Museum of Contemporary Arts and Crafts (Morocco) Museum of Modern Art and Architecture (Mozambia) Museums of Contemporary Art and Design (Micropolitan Art) Museum (Madrid, Morocco) Museum and Art Gallery (Muzambica, Morocco\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Comme j'ai augmenter le max-length 128, c'est pour cela le chat à plus bavarder.\n",
    "# l'allucination peut s'expliquer par le fait qu'il y a eu mois d'input et d'output lors d' l'entrainement"
   ],
   "metadata": {
    "id": "4ccKUUlUwFJW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "W6P7QYG_h6eE"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}