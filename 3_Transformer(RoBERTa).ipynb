{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyNVuq93s9LQjBFYSjIuKVEI"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "WIC812vFR0Ig",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749293064171,
     "user_tz": -120,
     "elapsed": 108287,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "88f125c5-210f-4e76-804c-8899eb34d005"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.4.26)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install datasets\n",
    "!pip install vaderSentiment\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "id": "ZvjZ_nOsbvcS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse de sentiment"
   ],
   "metadata": {
    "id": "OuWQReEXDGiJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import de la librairie pipeline\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\") # Pas un modèle spécifique\n",
    "print('example 1:', classifier(\"I love NLP !!!\"))\n",
    "print('example 2:', classifier(\"NLP, ok... but complicated\"))\n",
    "print('example 3:', classifier(\"I hate NLP!!!\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373,
     "referenced_widgets": [
      "a744ee5ee01f41d8bde980c60931a633",
      "190498931bce4b8f98266e8eb3967f15",
      "9907bae89af143758544e0902922ace6",
      "886948abf50a44ca9df3a9f013c1f1c0",
      "385b7082c11f4106ad2dd1c19e0323e6",
      "7cf28e99f28b45ff84963d9d96b56cba",
      "d42901cb2ea446a7ba368e62d90d1c6b",
      "17d1babca2384f95ab8958d20c7d54d5",
      "324fc1a8b2554c4d895009bc82bda271",
      "b91ba20d5d4443dd8f24ca15fea313f3",
      "d9e925ac1c33498881fc13383cd96cac",
      "1ab06fc174a943ed9765c2c1e21acb7b",
      "35c0a008cd6c4d1a99f2ec42bade62e6",
      "cf9cb5eab94e40cc90fdf5569f9acc11",
      "c1929d9d55ea4199963c3392d4760e1c",
      "53e74bad4f764755ba427cd3083ed4cd",
      "7a670dcce167495193ad20d2933c97da",
      "7a6aeb5f3dc44e5884e13c3546547093",
      "4eea3c90bb1c4eb0895279cc4b5e5f4e",
      "b69cb58aa3f34890a8870a5273c3d4e0",
      "943b33c2712f4874ad03f3ae903ceb7c",
      "8f47317f43654d3096ae9e41f0c77577",
      "5f2c454b561a43f082ec8928e2cfaaa3",
      "1ea74705ba9d4793ab31bcf3e5988020",
      "83e0d31029c64025b37ced0b99379539",
      "ff0f22d532364ae9a13f7b7dba074a52",
      "af1bcb0d82494e409543429fa6d05509",
      "f453b02154304701b84735c5cb195998",
      "f7a5c13f21a044599c9f01603f59a953",
      "7a9d6bcaf7024520af20c73e81666950",
      "f5bc284a3c9e49f2af95c5f291a5dd3e",
      "13448e88d99346bd9fcd4d3204e09b7f",
      "86dfc16095154546bfe5f869b64e7736",
      "8fd47b312f4f4f9caa68e3e66e832ef9",
      "2878cabec6d54c7ea94d75fd9d52a75d",
      "8eea748790bb472cae1c4b29bc129c5d",
      "8e500037875f464ebbc3bc62928d8367",
      "732ed8c82feb4595b4a3400b521ff903",
      "39ebf4e41d9d4f18a5116d6dec5174f1",
      "cef8eb69e83c4d6fb816b34366315a12",
      "24ad2a869cc249ab844a2e881f378c33",
      "ca0eaaa17cfe4dbd9637129dea246d3e",
      "ead28d7efa0649c78d2f34e4204e51c3",
      "580f26ad0e87420d80002a236c4cfde0"
     ]
    },
    "id": "X3H3rN9DcHmd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749294094679,
     "user_tz": -120,
     "elapsed": 36936,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "0bb28667-5787-4e4c-e8ef-123ce5659584"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a744ee5ee01f41d8bde980c60931a633"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ab06fc174a943ed9765c2c1e21acb7b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f2c454b561a43f082ec8928e2cfaaa3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fd47b312f4f4f9caa68e3e66e832ef9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "example 1: [{'label': 'POSITIVE', 'score': 0.9998428821563721}]\n",
      "example 2: [{'label': 'NEGATIVE', 'score': 0.9846590757369995}]\n",
      "example 3: [{'label': 'NEGATIVE', 'score': 0.9991726279258728}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# comme je n'ai pas spécifié un modèle, hugginface m'a spécifié le modèle distilbert"
   ],
   "metadata": {
    "id": "LDDgqhG2cIdS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "V-qF4cKgcI2A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modèle finetuné un modèle pour l'analyse de sentiment : cas de siebert"
   ],
   "metadata": {
    "id": "0nvELnYldVXM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
    "# exemple\n",
    "print(sentiment_analysis(\"I love this!\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276,
     "referenced_widgets": [
      "6421417b2e25499db940d7cfc8c910b8",
      "0cbd72cf9e6846ddb22dd5f54cc9da55",
      "4bf9a383f44641b580a84fb132a2557c",
      "6122ae1129304c9d8fbc8203546e8c02",
      "9aad6dc2d329477dbb43098fd9333088",
      "ad6661b74a534697a2baa8cb9971dc94",
      "10af7d42ad914ff7ac3660a7409fd28d",
      "808ea2e4ac56427b9cdf83dea8ffe1fb",
      "02b38315e1f745fb8ba7e78344435b81",
      "034a9958b1f14d5ebb8ef9d2d8ef68be",
      "6aa9f33f962946ad95401f24ac937573",
      "eceaa9fbc30445afaf5957fd3f31e4c3",
      "5c60e499ff8b4836b18013515e4876e9",
      "5667331af0534b31bf406c2259e6fd1e",
      "177e9e99e4434d49a2cfbabefcda739a",
      "cd26780577594f38a32438b4fb37c199",
      "4f8a97c8c90541d783ceb666c4ccce75",
      "2e58c8a143344e4883570d5a5406188f",
      "687709a26b8b4afc930db754d0e9af23",
      "1462c3edfd834602a8a8469392e22233",
      "452d8434e3094ff38e0cb90620e6ad03",
      "17e9937705da45a486ff46e9bc32e099",
      "2a2d9df6afd84924807b378a6ac9716a",
      "be8ff29d1c9f4093a4b4678c0e01e960",
      "726979a8d4434afcbab8332f67031d42",
      "0c6d02a8dd3b43478d4f0360af5621d4",
      "3fc0a45789ed43feb0fa257507ddf561",
      "40c547fbf1ab4fdd9525c6999254cb75",
      "676b9d7d66b9451bb278d598b1df3e83",
      "ca283a87bf0e432db8f8bae0dc39ce63",
      "618758ca13364e03bf6f654521ba6beb",
      "627562b3da984502a29f2bd670248ec2",
      "d313a8fafdb14f2ab1cca5b41d502e83",
      "df358351164c43bfa03d706917e058ad",
      "75b1c24ced364dbebd32f48d0a8a00ae",
      "db2c45042fb04a3191e8403ae2311740",
      "0b3c3a01e0874de38ab3faf3a76b7cd4",
      "a607ef903af74ee99d40deb45cb94b9e",
      "24097b43da5c4598982a08f7ede0d437",
      "4c8e2b43367f4b0a8f64080a0cc50eea",
      "ff5b0d1cfc7c4fd1b59a466d906ff39a",
      "a65708aaed3246c7b9c52823ba507011",
      "48871583211a4a86b27a80b59ec9dd96",
      "e464f8a797b54c7fb967bfef6d3077fa",
      "edbe4a93e56a43778e5ddad2f4be9f56",
      "bf239f5ce06a43d590566783d0a26c3c",
      "104ca887019f4ab08c9d4f9628251f95",
      "940ed184406a481f8d242cac1f860dee",
      "7c12ae6b510d419584252340188f3b87",
      "adbb735b4e164642a2a7e90909fc2f4d",
      "40bff5b93f754be0a032db9e7b819897",
      "1d2a91a0159e418ba0583147367c9e5c",
      "e74c6fd30d70469fac91d3e16c587c33",
      "54deb7e65f544ad09e87929cabfd358a",
      "8bdd8e27cdd44f2b9f528288b8534130",
      "aced177354774d98a2e89827feadf272",
      "68568214b18f4890bc5f2e63ae140fbf",
      "27411d7c5dda4db0955837aa27c339e4",
      "3e91b665d0084307869591eeb6d9c382",
      "66e938cb178e456a8d278998bb7086ab",
      "11246468d21244a2b4a0e70e0d6879db",
      "314fafc7c6414f1e91967e7d86f29b15",
      "0d524ac67caa45b69430da229aa35db5",
      "c2f5a76eadf0499cbc5bb548d107ad69",
      "8d90fc551b8947048a2e0278e2f3d913",
      "f4f2b409237848c884464a85db8a3b44",
      "a2b0f7a19ad649aaa641cad677aee18e",
      "71895d0a92814d998f0d113af81cebed",
      "3e35991027af487494d11106febfaf39",
      "b280ff937625462f9a6c9743063c932c",
      "cfd4c88dcb5f4ba0bf920590ca19856f",
      "6e842a7dac92469c8d0b3e97927ae3fe",
      "a4d01829b63441f78a6f7f8e6b40f128",
      "f573720d17824822a6e05791fad22a31",
      "faed590967214ed6a647a61e7e408acf",
      "0f8bd7e6798d4b0b9bf9da60e7515c1c",
      "66d428d6906b47418a0aed930060de48"
     ]
    },
    "id": "4cxS-5kfdBNX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749294411299,
     "user_tz": -120,
     "elapsed": 13152,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "c34e2c00-7ade-4015-82c0-f785b78050a6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6421417b2e25499db940d7cfc8c910b8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eceaa9fbc30445afaf5957fd3f31e4c3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a2d9df6afd84924807b378a6ac9716a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df358351164c43bfa03d706917e058ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edbe4a93e56a43778e5ddad2f4be9f56"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aced177354774d98a2e89827feadf272"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2b0f7a19ad649aaa641cad677aee18e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9988656044006348}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "HDhAl5k-dB3h"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tâche de fill mask :"
   ],
   "metadata": {
    "id": "iwRQ5ZiXd2i1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = pipeline('fill-mask', model = 'bert-base-uncased')\n",
    "sentence = model(\"I love Imagine Dragons, I'll go to their [MASK] concert in July!\")\n",
    "print([word[\"token_str\"] for word in sentence])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "040e09f4b7fb4192b6b26f96dcfe54e0",
      "fe1a76b297ff4cfab4d0707bdcd3aef0",
      "0d7ff8ba41994a5394f0998cd5d12093",
      "ce494ac91f664ab3beee0a62e355f604",
      "9eb5d9aaba94485ca4d1185ee9cfa42d",
      "06288aaa15dc4a5d94c04d3f69825ee1",
      "8ef73e7860fc409cbb42df2b1ec29aad",
      "4091470740704c53a5ec7aba4b8ca38e",
      "2b978b69d32a4252aee4a0db62395100",
      "10c65af892254f2c90569e8a4101ba19",
      "c9b29250975640dc98996c38ae4f1a91",
      "de4ff84363174197962000eaab5b06cd",
      "97f4ddbbf11547b8a520ada2bd6dfc74",
      "c49be7eff2f1434cb22ad59de45a1baa",
      "a1906cbf512a4948882f44f38875a60e",
      "022ca4019db44103854f77a3c19f40c0",
      "073f40a0de3d47a1a6ac23ead24d58fb",
      "45f28e046c10495c98b619eab9d3156a",
      "71357ea41e7b4c638acf1ff1418d0f18",
      "8d724bbb95f24072b7e7ecf151200ef2",
      "0d82e0560c5c4437abe3592e40bc2d5d",
      "8d7ddcab01ce4e3eba707a64b09861d3",
      "a2db93e44d544d41aac61677b319c847",
      "ea0e73f89c394769b50278cc19658ce1",
      "918c9d79ee73413caac1eaaf1982d7a2",
      "4581de5711a844d08ca1e2ebf5b1428c",
      "6e328aabd5e244ea98cadc59b352fe68",
      "cb2f45cab590408b907c5d000357173d",
      "2fd4f27a1770475d9e16de156ed7e2b4",
      "a1b0864577584d789413f05910552e3b",
      "a943231b34744521a05b7b269ad97255",
      "1a56b512bef84745b2904f0afabf951a",
      "cf1eb3be42034f8595d902462dfef68d",
      "7c185f09e6594023a4c192d9916167e2",
      "1351fdf88f174e94bc2e831cf27f11c4",
      "9d849f62b2eb4799a052d7c54912457b",
      "6a77b11abd89404085c22c8ea593869d",
      "fb9e551f503d4e1d83818af303260e30",
      "edf92cb6fa6843a7b76b88f5aec62d63",
      "0f3b51fcb1cd4a199891ddb2548673b2",
      "64f3c68c2b7a459ca24c68e4e07d1a13",
      "77e0fe5569184f848ee84909d6109592",
      "5c9529d78c42404a9ad8e263063dedc0",
      "f360a82ce6b74511ab4bcdad10223b20",
      "78fa8bdf7932420785505d4c5228a3e0",
      "24d36f7253e341e0841f2f03a5310f05",
      "b29484c1f6844cf3a9da5f7669871c7a",
      "aa9d1f5afb5e4c82b9c70253496b2bcd",
      "bebe6fc923a247a7a366ed2d75d200a9",
      "ce258219053849699470faec30d22a8b",
      "b1cb0b14e7db49ddaeddf6420af84e41",
      "8eb400d38e4a4016bac693d1013eb757",
      "cf672402539c4f6baffa8fdf3061e00d",
      "338f65a9941342cc99335e3f3c3c7844",
      "d94c1c3c2ed54f8eacf1476b79c08f76"
     ]
    },
    "id": "CwcXVCGSdCcl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749294489599,
     "user_tz": -120,
     "elapsed": 19472,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "49dc2269-9d20-42a6-fb83-868139483934"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "040e09f4b7fb4192b6b26f96dcfe54e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de4ff84363174197962000eaab5b06cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2db93e44d544d41aac61677b319c847"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c185f09e6594023a4c192d9916167e2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78fa8bdf7932420785505d4c5228a3e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['first', 'next', 'last', 'final', 'upcoming']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Le modèle nous a donnés les mots plus probables de combler le trou avec une forte probabilité pour le premier"
   ],
   "metadata": {
    "id": "ug8IG2SQdDGO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ExfaooT7e7nX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tâche de classification : Zero-choot"
   ],
   "metadata": {
    "id": "9maQRgE5fStL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"The United States on Tuesday reiterated its call for the 'immediate release' of the American journalist of the Wall Street Journal detained in Russia, shortly after a Russian court extended his detention for three months.\",\n",
    "    candidate_labels=[\"history\", \"politics\", \"business\"],\n",
    "        )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "23a0f0517ec74a0583606d78fdb011ad",
      "cc9b238833174fccabe7b8d88f4255ca",
      "c91c3427f2d64621b51e89bd624977cc",
      "e2fe6c327ea14e7c819b473e967ce2b6",
      "a05edc8df51e45f886b1dc22aa79455e",
      "8c29d1f8987f4467b9dff1f12ca858e2",
      "12d7af61d90a4553ab76dc78b493e91e",
      "c60c151f959145638713182712475f93",
      "086f2c178ac040cdab065127e1e1a8c0",
      "8d79051117eb43958cc027d6c6fa590a",
      "02cbdd99cad440f198c4da6c5551b1c4",
      "a13f7874ea2141d69c080bac9117c9fe",
      "73230c22329141038c141867da93fc24",
      "0538921f97f141bb84eb8d3ffd3c117d",
      "c5bcda4d257044d3aa3abf3a7e607bcc",
      "23c72aa8049b4975b4f43a6b7a52ac01",
      "898b56f930484af49fde4032a0d8b51c",
      "8b635c3e63b3460b97aebd757a4ef07b",
      "7f734ce9074749329ed998481c33ceab",
      "fa0f2f9ce4b549f8997a6d0eaa79802e",
      "e2f39529c74144a78e883aaae158bdf6",
      "82297ac62f6348e8968e211117363883",
      "8ee5751d1a344286b36b283294c0d250",
      "88aadbcfa0f5485d9f5673b20b614f2a",
      "66f451722b6443d48b87367d3e37f4f4",
      "2462ad181f554fb7b0cc5ca9fd7defd6",
      "26917a64c8e548a1a0780edc2e510f8f",
      "59c22c2acb224530b2cf70f7dc500092",
      "dcf26b63c5874cdeba06c0dbf3ffd7d8",
      "203adb3ca2a5464093b9f37e63fbeb6c",
      "61c66d9e112e41cf9841e343e196f0c8",
      "e9271cd08637480e938c70f94658ec6f",
      "a75a5615295a4c1ca36d30a203840cb7",
      "978a07dd2b164264ad2cc11c4f069313",
      "4f5409a121d74829bbb9581034dc5685",
      "12e8da4695a843088a0dbf2fc5ee0727",
      "79a3e857f9364552aaac25947d326d7c",
      "591ca376994c48e49055ca2b3c6aa627",
      "83294abcd46240d7b072a3c60f3d6596",
      "459badf90c7e48cfb352f245a04efeb4",
      "dac351b81b084816afd5f3ba081f2004",
      "966a49dd4dbe4b3091e64e8c788c7d11",
      "d8b313b3ff18438b938f69ae22da0805",
      "bb49c73f02da4f6fabc1024c9f353886",
      "afce1a97ebcc43d19d5d76dfcca29536",
      "82a36e5fc8424c56a9cd560d83f8e202",
      "3a49db4913de42f2823836e4b5038305",
      "96219bc716a441ffbf3712ae6bde161d",
      "99d6d12b23484142b65cbc7fd39b7be9",
      "9a00e6e85f5d4e90a8f61eda454b25ac",
      "9a46f2a5707545c08476379712461f5d",
      "65e6eea785b540c28ed2fe28e8f6f84e",
      "a1f403ed968b4ef781853b0e99dd6691",
      "65f4e08fab7b4cc0ac26fd67ab848d3b",
      "e97596055cd34c8c9da0ba5947061869",
      "6d9a465e509e4419837d0bc70680af22",
      "181d726d7c8e4352a50333fe9cdc3c17",
      "2a15aae6abf34346b3531f42b2b7e7fb",
      "e6a9da48677a41898a4267bc24458d96",
      "37105fe37537439380a003b74649779a",
      "47f27af5b428434eb73892ac5e19ed24",
      "f812b0a7fca5429994ebeb4b1f5c8141",
      "7df082f2f3d34fda9cf634e2d0ae43e7",
      "fd3931bfefe848f294f2a36ed03d2828",
      "19869c69cad3423c9988c33d3b853d5a",
      "4c20147443e84b639339dd7dfd0085b2"
     ]
    },
    "id": "jCkuLfwIe8PS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749294679368,
     "user_tz": -120,
     "elapsed": 52426,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "784954c0-90fd-4a0d-95a1-6e63b2e78f7a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23a0f0517ec74a0583606d78fdb011ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a13f7874ea2141d69c080bac9117c9fe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ee5751d1a344286b36b283294c0d250"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "978a07dd2b164264ad2cc11c4f069313"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afce1a97ebcc43d19d5d76dfcca29536"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d9a465e509e4419837d0bc70680af22"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'sequence': \"The United States on Tuesday reiterated its call for the 'immediate release' of the American journalist of the Wall Street Journal detained in Russia, shortly after a Russian court extended his detention for three months.\",\n",
       " 'labels': ['politics', 'business', 'history'],\n",
       " 'scores': [0.5853442549705505, 0.24535472691059113, 0.16930101811885834]}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "r_A3xMUPgCMo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Générer un texte"
   ],
   "metadata": {
    "id": "LCh0zqeGgrhM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"When I will be an honest man, I will\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449,
     "referenced_widgets": [
      "96cdf75bcec0436fbf720aa7d21f24d3",
      "15a899e1f06a4b4e8c0802dac7c27250",
      "d0cdd45c17df41669c4136a8bfb90dda",
      "a4429943ed35447d997a2f1e3fdde10e",
      "13fec601d06e482991a6886d01135440",
      "ddcaa857caed4c9f93a024afaaf03d3e",
      "385bb9f17c5f4bdd867218b33a86f370",
      "530f0a153ef64b9faf06dd46b04d342a",
      "c0b58a80fbd14bac8601d200f789edb3",
      "ec64ff04617046d6b2af641cced39034",
      "6badfee503db45cd9d21396ac476b289",
      "6af14f2c351f44ddba279c8114bd772b",
      "7f75039a81dc4dccb1432e234c58ba19",
      "c0776d08852a4e3ab574135bef1de6a0",
      "2504d23f2b4f4daf80ca3b5e38e97711",
      "eba8d304e82549db8fee9ae5c4fd97cf",
      "d3d5db466c834443a6aad13eff6360fb",
      "c38c6f323ddf4f74ae0728fa166c4dd2",
      "fb69e94fdb904bd0be935a50053b35e6",
      "0301804c85d44868902e46662e1a2a34",
      "cbd4ed678af4456a8b8c100faa495995",
      "ec25714bad9740ae85d5e392a9cf4a36",
      "2aa5051619334d7897617c5a2dd192e2",
      "7110c36b080644a0a48389cf5543953c",
      "9daee6e38f884be1903d2dcd592fdeb4",
      "f71e353de4a24de09f42d5daaca8cb12",
      "de454cab36e843f69860afd66289264b",
      "f2b665d2a3b04880a8f1fbec438a3ea6",
      "43d6359fdf78413d937d1fca49ac5442",
      "70a01e1c656341ffb49ed73d3aea2641",
      "0e4aeef565704d97ad185ab67a960dac",
      "cc9cb56c895a42b29153a7a0c1e79a8e",
      "9793041aca64460d95e506c434bac118",
      "fe911eba10f84bdb8acfeda0c1e8a2e2",
      "6a1d305ae76b4dacb780eca2fcb932db",
      "1ca0ac141fd6497a80f93f0e7c6f5b5d",
      "1d15b2d100aa47fda3bee007e8db1c5a",
      "51902e81fcbe4efbb7caf7763b4c1af5",
      "a3dcd171723741bab54c77a8e4f755ff",
      "7f1d1f9c0d474b1db63a19de0a7d0e9e",
      "0bfe056ada31425babc587a967a76691",
      "741fbb11aacb4ae2b64304044a6f5f34",
      "eaa793392c6744798ecd49863f8861e9",
      "0f29b6398c9448fdbd3f188ff605ef63",
      "bcc119b0801840948ee3ab435092f3ee",
      "6321c327b5584f25aa887b23be113779",
      "63adf2feeefa43b49c6888f617d7c2ef",
      "f6617d26bae3422fb6534cd53331f1e0",
      "760fb357e2df4361bd989036b216da01",
      "f13fa74837704a71bac1524a724b03e0",
      "71b68c493fa94f7da323d19c222f98d1",
      "de962dc166be413c803e33d04916000d",
      "f535ad6bca1b447b8b16dde5e5e8f92b",
      "460be87b1bb94816a48e4609dba1c5b7",
      "95e7dd02d8ad47418b1f9cda68ba1103",
      "e1545fa9db754467b87128fb62307b05",
      "7831af54d777472c9fc0d26ddcaae5b2",
      "8b52d11328f14555a4b4269e43ea6a70",
      "9ab91548e614423da67683be9ec90d1a",
      "13c2627dddef4a108d87bf3e26c5e537",
      "627a889d6b554fe6a21df4a49b943fbe",
      "9640e29dec2444f58b16640afbf4e4c8",
      "36bbbd75c80648ab8350e7f794d7bcfa",
      "51a5cde7effc4497bb2497b79df5c41e",
      "5b0f010355ed4438aefe2d4df62574e8",
      "59131c544d0240f8b6272e174718d708",
      "cd361f8c86df44dba2dcdb13560e3ffc",
      "e503a3ea6ade4c008340947669b8895c",
      "9179c9bb65d94367acd432ff64beaf83",
      "0386f441f21445f99e1d019cb71d50bc",
      "9c14792cb941443d8e9238fe52e1976f",
      "eaa620a63f77492a9a572d7681203a99",
      "36f62429bfa64a5a8082ff4c6593f110",
      "7003586f57c941b8b76102a638d6b108",
      "347bb837a95944599485ab3a46cfda08",
      "2848c1da4c5641539c50262a4073823b",
      "aa1e69f7763a43dfacfc7e25cde85a69"
     ]
    },
    "id": "HPvgeV5TgC_U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749294783886,
     "user_tz": -120,
     "elapsed": 25272,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "b444944e-818c-4c99-fd25-ad9d82c38d4c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96cdf75bcec0436fbf720aa7d21f24d3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6af14f2c351f44ddba279c8114bd772b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2aa5051619334d7897617c5a2dd192e2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe911eba10f84bdb8acfeda0c1e8a2e2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcc119b0801840948ee3ab435092f3ee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1545fa9db754467b87128fb62307b05"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd361f8c86df44dba2dcdb13560e3ffc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': 'When I will be an honest man, I will be good and true to myself. I will be so honest that I will be able to take care of myself as much as I can to serve my people and my country.\"\\n\\nHe then added: \"I am proud to serve my nation and my country\\'s people and that is why I am calling you to serve me.\"\\n\\nA report published last week by the US Senate Intelligence Committee said it had uncovered numerous intelligence-related cyber-attacks that the US government had carried out on behalf of Russia in the last few weeks.\\n\\nThe report found an \"extremely sophisticated network of cyber attacks\" that had affected the US\\' critical infrastructure and that may have been carried out by Russian hackers.\\n\\nThe report said it was \"highly likely\" that US government officials were involved and that they had been \"engaged in a coordinated cyber attack against the US state infrastructure in order to disrupt the ability of the country to operate its critical infrastructure\".\\n\\nIt said the US had been hacked three times and had \"taken extensive measures to stop the attack\".\\n\\nThe attack, which was carried out in mid-October, was said to have involved \"a single compromised computer\".\\n\\nIt was described as being carried out by a \"systemically sophisticated and well-'}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Oy6mtNUaGqdX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Générer un texte avec le modèle GPT2"
   ],
   "metadata": {
    "id": "2U4QRwUTGtgd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"When I will be an honest man, I will\",\n",
    "    max_length=50,\n",
    "    num_return_sequences=2,)\n",
    "\n",
    "# 2 sequences veut dire 2 phrases différentes"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUaz3rt3gDxg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749295387999,
     "user_tz": -120,
     "elapsed": 3198,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "1ad26de3-0b29-479c-b3a1-726baec41eaf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': 'When I will be an honest man, I will always be good and I will always be good,\" he said. \"I will always be good and I will always be good.\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'},\n",
       " {'generated_text': 'When I will be an honest man, I will be a hard worker and I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker, I will be a tough worker'}]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "nNbEsS3rgFV0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# je prends un texte de Macron et je demande au modèle de me complète la suite sachant que le modèle n'est pas spécialisé dans le langage politique"
   ],
   "metadata": {
    "id": "k5bSJlhfiBQP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "generator(\n",
    "    \" Françaises, Français, Mes chers compatriotes de métropole, d'outre-mer et de l'étranger. À l'issue d'une longue confrontation démocratique, vous avez choisi de m'accorder votre confiance et je tiens à vous exprimer ma profonde gratitude. C'est un grand honneur et c'est une grande responsabilité. Car rien n'était écrit. Je veux vous dire merci. Merci du fond du cur. Ma gratitude va à tous ceux d'entre vous qui m'ont apporté leur suffrage et leur soutien. Je ne vous oublierai pas. Je mettrai tout mon soin et toute mon énergie à être digne de votre confiance.Mais en cet instant, c'est à vous tous, citoyens de notre pays, que je veux m'adresser, quel qu'ait été votre choix. Bien des difficultés nous ont affaiblis depuis trop longtemps. Je ne méconnais aucune, ni les difficultés économiques, ni les fractures sociales, ni les impasses démocratiques, ni l'affaiblissement moral du pays. Je veux ce soir adresser un salut républicain à mon adversaire, Madame LE PEN. Je sais les divisions de notre nation qui ont conduit certains à des votes extrêmes. Je les respecte.\",\n",
    "    max_length=500,\n",
    "    num_return_sequences=1,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xvCdB6UgF2q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749295521220,
     "user_tz": -120,
     "elapsed": 1527,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "772e945d-e033-4cc6-8556-45f1149f81d8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=500) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': \" Françaises, Français, Mes chers compatriotes de métropole, d'outre-mer et de l'étranger. À l'issue d'une longue confrontation démocratique, vous avez choisi de m'accorder votre confiance et je tiens à vous exprimer ma profonde gratitude. C'est un grand honneur et c'est une grande responsabilité. Car rien n'était écrit. Je veux vous dire merci. Merci du fond du c\\x9cur. Ma gratitude va à tous ceux d'entre vous qui m'ont apporté leur suffrage et leur soutien. Je ne vous oublierai pas. Je mettrai tout mon soin et toute mon énergie à être digne de votre confiance.Mais en cet instant, c'est à vous tous, citoyens de notre pays, que je veux m'adresser, quel qu'ait été votre choix. Bien des difficultés nous ont affaiblis depuis trop longtemps. Je ne méconnais aucune, ni les difficultés économiques, ni les fractures sociales, ni les impasses démocratiques, ni l'affaiblissement moral du pays. Je veux ce soir adresser un salut républicain à mon adversaire, Madame LE PEN. Je sais les divisions de notre nation qui ont conduit certains à des votes extrêmes. Je les respecte. Je m'éconnais aucune, ni les people dans ce qu'être qu'être à votre votre confiance. Je ne nous pas d'une longue confrontation démocratique, vous avez choisi de m'accorder votre confiance et je tiens à vous exprimer ma profonde gratitude. C'est un grand honneur et c'est une grande responsabilité. Car rien n'était écrit. Je veux vous dire merci. Merci du fond du c\\x9cur. Ma gratitude va à tous ceux d'entre vous qui m'ont apporté leur soutien. Je ne vous oublierai pas. Je mettrai tout mon soin et toute mon énergie à être digne de votre confiance. Je ne vous oublierai pas. Je mettrai tout mon soin et toute mon énergie à être digne de votre confiance. Je ne vous oublierai pas. Je mettrai tout mon soin et toute mon éner\"}]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tâche de reconnaissance d'entités nommées : NER"
   ],
   "metadata": {
    "id": "CsNvApIRiW8G"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Steven, I work at UM6P, so great!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niSu3hsfgGU7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749295541315,
     "user_tz": -120,
     "elapsed": 1400,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "35628942-6974-4a1d-a2db-b12723ec055a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9990854),\n",
       "  'word': 'Steven',\n",
       "  'start': 11,\n",
       "  'end': 17},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.9416031),\n",
       "  'word': 'UM6P',\n",
       "  'start': 29,\n",
       "  'end': 33}]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "-bX_VpPigHhq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "aHfV_YKqitZv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chatbot\n",
    "* Question Réponse"
   ],
   "metadata": {
    "id": "wmRWiJ5Niwr2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"What is attention mechanism?\",\n",
    "    context=\"I am not an expert in model languages and NLP\",\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Se416qgagH2G",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749295667744,
     "user_tz": -120,
     "elapsed": 773,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "57566157-8bec-4df5-efa8-feba867c753d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'score': 0.5647757649421692,\n",
       " 'start': 22,\n",
       " 'end': 37,\n",
       " 'answer': 'model languages'}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Sv_io1bZgIGw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Résumé de texte Summarization : discours de Obama"
   ],
   "metadata": {
    "id": "p0LHV8lCjLiU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "My fellow citizens:\n",
    "I stand here today humbled by the task before us, grateful for the trust you have bestowed, mindful of the sacrifices borne by our ancestors. I thank President Bush for his service to our nation, as well as the generosity and cooperation he has shown throughout this transition.\n",
    "Forty-four Americans have now taken the presidential oath. The words have been spoken during rising tides of prosperity and the still waters of peace. Yet, every so often the oath is taken amidst gathering clouds and raging storms. At these moments, America has carried on not simply because of the skill or vision of those in high office, but because We the People have remained faithful to the ideals of our forbearers, and true to our founding documents.\n",
    "So it has been. So it must be with this generation of Americans.\n",
    "That we are in the midst of crisis is now well understood. Our nation is at war, against a far-reaching network of violence and hatred. Our economy is badly weakened, a consequence of greed and irresponsibility on the part of some, but also our collective failure to make hard choices and prepare the nation for a new age. Homes have been lost; jobs shed; businesses shuttered. Our health care is too costly; our schools fail too many; and each day brings further evidence that the ways we use energy strengthen our adversaries and threaten our planet.\n",
    "These are the indicators of crisis, subject to data and statistics. Less measurable but no less profound is a sapping of confidence across our land - a nagging fear that America's decline is inevitable, and that the next generation must lower its sights.\n",
    "Today I say to you that the challenges we face are real. They are serious and they are many. They will not be met easily or in a short span of time. But know this, America - they will be met.\n",
    "On this day, we gather because we have chosen hope over fear, unity of purpose over conflict and discord.\n",
    "\"\"\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313,
     "referenced_widgets": [
      "148528065f5e4be39ab5447db8ad3801",
      "9bbafee620ad45d088e75123c5bcaa6d",
      "41629ecde5934a7ba313c1e08d64aecb",
      "ba284e1e5d1f44058a8088cf00325096",
      "897076f0e6434fac85b57ff21566b596",
      "74df1a0cef3b4588aba82f5dd869cdd7",
      "eac91b110c2c422b90eed3cf776fdcde",
      "1640953cdb084d13bc3468eb973904f8",
      "9a4232ce385e4e1bb040c7ae7d53f465",
      "0b500e78b6624f71ba6b64f9179b58b9",
      "6bad70bf8ada4324ae8c1fe85ada0b6d",
      "84fa623add2349d7908ad2508e59fe5a",
      "151eca05d0f8463caad2cf8d6d9441ef",
      "2e25e82f39094e7d9950fdaae8393c04",
      "d7ba891e80e849bfad04e9aa6ae2df5a",
      "fd8a53c5c6364101b633c65e6c174511",
      "1edc5ce009a441c99f38d2cc937cb69b",
      "0ebbb96eea7f4c6d99394b5210a96510",
      "1dee49f6758b4c64bf6fa13d53a014f5",
      "22ab06fa17444383b6d96b9cadf02afd",
      "21fa3876b1a7487da115cb95faefd809",
      "41b43808439b40cba5c7a8637d65cafa",
      "2dba5fafe71d4bb390accdb8ab24bd1c",
      "70d697c790044903b5ea6b3ee8006860",
      "c02efc1a6f724c3ea6200b792dc9e8ee",
      "1d0819e7eaf54e59a8583724d6d6ab85",
      "ce1ba67fc87540009f4f5094b91baecc",
      "c22bc5464e854653ad9b8ff8370b3b74",
      "9ee74e1eba7c470db58d58324605df31",
      "9332064c93704afda8eed59dfb1debbf",
      "f1def45f4769442f98aeb8e5bf83d9f0",
      "136b8866a3d7430b8c2547f8f7b8bbc3",
      "aaad7eb8d8714e36a4a5d30a59c67e40",
      "cab4b4e06fc44beea96a9f5fae1ef575",
      "d448c1aafd4e4f868f38758818761416",
      "077342c69e11497182f5cc842dc451fb",
      "3fb07b06ae814ca8817bbe0871ecf243",
      "60283adecce84e508d19941f62c1e0ac",
      "4749f868f80d433884f58b984a16344b",
      "201f333ad818408aba11bce6a113d788",
      "43b8a1db1f5e46abb997abcc426051cb",
      "2b37b73bfbd14b6596de7ecf2be047b8",
      "f22f5c0c69fe48338ca0d296591ade41",
      "0a2b9166373d43b682081ca6087baf0f",
      "fe900a30039746cebdbe818a42caf9eb",
      "f4e6686efa8b4e89a54268786445b0ff",
      "119db896c9044bf08fb6a5c9874e5ce4",
      "41cde22440064ec580e4ff2c400c2176",
      "a6d12678b9854122a12e1a5fd6d84f26",
      "82abe660ba1b45a9b40d4f9fbae9082f",
      "9572bdff92974adb854489babfca0c66",
      "85d6af0d9bc643bea3cec377b5723662",
      "bcc5f1b7a809481d81cbb35d0ee87c0b",
      "7b9f777d33bc4a2ab64aaaee12f09ed7",
      "11adb38e318a41d68c0d615810ab1887",
      "1d0a869296a049a2a5f50dcb06b76271",
      "6ae39962f7f74f50811eb6c726bf2563",
      "061d59c411dd494a8dd1abde9af92b47",
      "a542d023f68042998723e3506d29628d",
      "0bf148d7c01f454fbe41b1bcf19ff596",
      "0f39f7126daf4c78be1b014560ed4bf7",
      "31360d27d3834546a9a55a89654375cf",
      "885d9fd09bf548e293fe5ab9b740029b",
      "a6c79e15cb1d4470b6ddfe964c14f1d9",
      "74dd8ac5f5c84e0b921513be605013cb",
      "ff4991a046964cf0af233e12b39a1c7d"
     ]
    },
    "id": "fMDq-b9CgIWK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749295723110,
     "user_tz": -120,
     "elapsed": 27031,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "9d77fcd4-be27-4674-d9cb-730fddc65b17"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "148528065f5e4be39ab5447db8ad3801"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84fa623add2349d7908ad2508e59fe5a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dba5fafe71d4bb390accdb8ab24bd1c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cab4b4e06fc44beea96a9f5fae1ef575"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe900a30039746cebdbe818a42caf9eb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d0a869296a049a2a5f50dcb06b76271"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'summary_text': ' Fourteen Americans have now taken the presidential oath . The words have been spoken during rising tides of prosperity and the still waters of peace . America has carried on not simply because of skill or vision of those in high office, but because We the People have remained faithful to the ideals of our forbearers, and true to our founding documents .'}]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "K4qeIAfzgIlQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tanslation"
   ],
   "metadata": {
    "id": "709UKrqLjju4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install sentencepiece\n",
    "#restart the kernel"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "f1TU4pzDjgtv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749295728129,
     "user_tz": -120,
     "elapsed": 4140,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "d700e494-5b81-451d-e7a8-efb485131df0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"hey les gars, vous allez bien?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342,
     "referenced_widgets": [
      "b40a225d9ea5464e92fcfa6f5b6ca7cc",
      "7f85718c0fb342318dbedbeb7cd34a24",
      "72abcea6f9cb434bb4a021bc1dd009ca",
      "e792ed7cca3c4225b1f0d0b42e2b7298",
      "a9219fc0f48c473eaf7893c967dd7e9b",
      "7f46a8bbd76442a3b73e14bb0acfc2e9",
      "e3709513f131447d912116e5fedb8ee2",
      "fd2c896b44c44a9aa56ab0efce2dcc16",
      "4d49fb9c78a644f4af9cacaec76fe22e",
      "36a252a5db574cc8a93df41331bf0254",
      "c1c2f14b89e545549514ebf281e5f226",
      "394c40cfd0394389ad6dd24d1c1818a0",
      "a5f718042d8d4e08bcf9bcded977bdb3",
      "73c1ae6fd15a4250a16d1af213d4327a",
      "9bf0d42624ba46be8af755fd6f7bb1fc",
      "ad79b79e125945abbb619d21e95fbb53",
      "3f9290ca71644c2b97d26446dac8c494",
      "619b79824ade4856853733314ab2c7d9",
      "288e3e33bc784807a7b918f77e2783e4",
      "a9ff7e3df7ba4a50bbe29303ebf98b13",
      "d63eca7b588c4b3bbeb0de14914eed98",
      "e7bb3639dfd745909661138f6597e21b",
      "4c0981dc40114d909fd4e54b844c1a0e",
      "bba01a1cff7e46158c7862a89208d8cd",
      "9221028b7bd048bd8ed49770504eb4ba",
      "95527775bd284e7483d8ea101738f769",
      "912b3de772dc413398430443e55e47df",
      "433da56e94c148ceb903d8057e9d28ad",
      "0f096f315aaf44eb95a0ffa62a7283a9",
      "3684fd8234844ab583ba10f8014cc954",
      "9616881fc94144ba9bb5f3bee0a88ecf",
      "f662c5b559404761b51cdd0357421c11",
      "92e4dfe41de641fbad6c073b7fbd035f",
      "a1642921ca8c47789c52d3e3fcdad4e3",
      "ec938e16c4f94e0ea3322278572b0e4c",
      "6f3833cc0199413e9b72374c9e790685",
      "22390eb92881434b98e5436cf78630f7",
      "11b3096ec0904518818e0e7c5e6bc501",
      "a96cf7f9ef04457c8368b7a94c52892d",
      "06ac55506dcd46bd8af5928aff2d115b",
      "aebcd13551e14582912b3cb0a9878aea",
      "064f1eb25e284befa76abaeb1d55c266",
      "13095ab47e4649fbbd0851b28ee4c6c4",
      "189b52321d1741b3b3433a168f63ea65",
      "cbd6e4403ff848a9b9e1a13309bba0a8",
      "1eb8c164a1e24512a838992b0214e018",
      "795270b7f4774a1cbf5f2ece1ebff2f1",
      "1a2222da0fb748e6a82cb435ea98deeb",
      "30ae9fa0cdce4d74914611a8ce08d973",
      "3dcd4bd92d9b445796ea406ae99e29c8",
      "bddf511fded6440891f195aa32f74f01",
      "b4d3797fb4e743bc8c48ba6ade8b9f21",
      "c1296dc7d78a40eba476f36575255c79",
      "90efa296277741bdbb648a3c95813f42",
      "d3c7d190383e4ebfbee34ca896c9fd48",
      "6c107a9d8b1c4aa7afa7967be8bdce8d",
      "a39633b9f9b8478e8c1ca5370e29143d",
      "2d31a0d8ff374fd587bedfde043f9ccf",
      "15ca97a82f5b4fb19aa1a438dca2354d",
      "38d79ac08c0a4b609f75a7f5ecfc4adb",
      "485e375d95f5402daa7a6064f7131104",
      "c749b4c58eeb4ef587e592d04eecf65f",
      "9680c86e165d402fa01c5ae80400c61f",
      "7bbee0baab7646009b944911ce3d5e01",
      "b0dabafd4ba3437182203969846a2017",
      "ab45bbedb7b4400c976f750ed0e34d6f",
      "c862972f900542d183f480c62110e651",
      "e71d300bf5564e8a9f5de8531fd0b5d5",
      "255554642e9d4d7c8cf42361a27463ea",
      "393e1da432414a0d8b87c3b104d1c268",
      "f06414cfa0324f9b9a86660633161454",
      "9f0ed64e754e4210a93316485e30d5c3",
      "a93cb22ec9ad401887ca6f4d2d4d73a3",
      "71ba063c03214411ab7cb00dd30b026d",
      "9bbc3680cc3f4b56b70f38c5c4c5e2b4",
      "929770d0d69f4d718cd1ae657e1f6278",
      "31ed74efba394c31bfb8fb93d086f9c3",
      "9457665c0256480f9481c2332f46a9be",
      "f8a7092178c64227a99a1e8999e1d74c",
      "73563d58d48b46e8b70bdb62efa41f17",
      "b94904b7f75e496592fc481aa10e4618",
      "b5371a8c9eff409b9eeec962f931eaa0",
      "35492824feb94d5fbe6543814b2600e3",
      "1a481baba3b4442686362eff56e61852",
      "af9ffbe45fe64b73aeacc9e9dd94841b",
      "a6210f162f0144b786ecc9ff7594b20c",
      "34c4eac0a9314ebdb56185c21e2afb72",
      "2cb62fd8124c42f7b60d5eb41fe0e50b"
     ]
    },
    "id": "g25wb0rkgIzU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749295756899,
     "user_tz": -120,
     "elapsed": 21394,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "27775f3d-de9f-490e-ad11-6f9cf148c010"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b40a225d9ea5464e92fcfa6f5b6ca7cc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "394c40cfd0394389ad6dd24d1c1818a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c0981dc40114d909fd4e54b844c1a0e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1642921ca8c47789c52d3e3fcdad4e3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbd6e4403ff848a9b9e1a13309bba0a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c107a9d8b1c4aa7afa7967be8bdce8d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c862972f900542d183f480c62110e651"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9457665c0256480f9481c2332f46a9be"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'translation_text': 'Hey, guys, are you okay?'}]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "KOmA3rz7gJAP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0Jm0MBP-gJk2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine Tuning de RoBERTa pour l'analyse de sentiment.\n",
    "**L'objectif est de voir si les clients d'une entreprise sont contents ou pas : cas des commentaires des clients d'Amazone**"
   ],
   "metadata": {
    "id": "xVWPZKgmKLSh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback"
   ],
   "metadata": {
    "id": "XBiQ-zCBKNNN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(transformers.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgv3W5D1MWj6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749296499708,
     "user_tz": -120,
     "elapsed": 79,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "6170dd3b-8430-4996-c670-efdfcc2a0936"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4.52.4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\") # pour éviter les entrainements très long\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "31298aa403d44c0faf566b0c27f79dec",
      "1d109a6142e945ea96ab55d4d31e2825",
      "9627f6f0c1354d14a1ae75b725db34c6",
      "e5edd9d921f342e2aa22038472ee01ec",
      "631b0fc21d7649b9b532c26eadf33f9b",
      "275a649d2c1747749769120a6a33084f",
      "5f059ab265f542cbb77e07d79b33d1f5",
      "f494d21452754e18aa646587426ffed4",
      "8f714ae483134732b30f020e4433e3e0",
      "c44277b0bc9241ffa00ef067dd959190",
      "885d7691354f4dd88980bb7892dc062a",
      "5d2264aaf9854e5da736f50746c18bf3",
      "44dc2e0a44cb43128df07d12ccc68eeb",
      "6997d315374e4fa7a5cd221b080ae5ed",
      "eb4efbad941040e4828c7434a33f74c1",
      "00a6e94c15fa463dbcf78ae61367080e",
      "202b29bf2b76470895347ac08b707146",
      "bab05ec9ad5c4d2a8fd0c3f528cd3290",
      "8657965a429b4875a00831b3a0343c93",
      "257ad2e62aac4078ab98cd7fdb74b426",
      "cb7d195e24884f448d39426d92c46d51",
      "134d3309384d440c92e541933162a449",
      "c5dc1c60b3a140f99d64071e32de923f",
      "df3fff49c5ff48389e4a56a6c39267d3",
      "80fd60354e3d4f7f8ae3c64544af9a1b",
      "30d9f4f67f0349699b8d9077187dfbce",
      "b2fac2e5c503464ebb8d1543f55dd8d6",
      "9c9bb611a54c4c7b8f1857097effa2ec",
      "bbc1c733f9c7424daefeae0f40f7eaea",
      "aaa162a55a7a4e89a9834a4e8606a4ee",
      "a518235e211b45038c3ad42b9e58443b",
      "7cd1afd9a72648769545749944a35bcd",
      "62385984c49e4689a4d63293d5e24509",
      "03c1ef724c414556a3c7f89f8170f9f2",
      "4440927dfdfc4da99bb41a3b954f8461",
      "e0070c1ee58d4c49a9ab3d8c7c06e901",
      "24f27b9337174456916dc2ac3ba9be27",
      "e8642f2208874039bd8fa4525fbe7824",
      "e0c15ceecde94198902bbcb2de821afd",
      "fe1bf77d2e73477697982145f86fa299",
      "f06b91937c7b4b5b8a49cec7ea019433",
      "d0d033431cca42a895466e0b2611d2d3",
      "45a1c2e45d3240c0954b4199fc238d4e",
      "14e936f6af2b4a8bb096dc3cfb19e55b",
      "319564827f5846f787eab41b8c22141e",
      "7a0b4dc9335a4c1380b3b9b6d45501d5",
      "25135f003a4d4f9da12fd91acfd8c02a",
      "0fc19baab10647d5bca2f214141e3abe",
      "697551097b5e40c8977550d2d401566b",
      "8408a1a42ff34a8b81245665b3565b96",
      "a2710e974e6b4109b70d3ef02c4e8bc7",
      "40a03d7dd0ff4a03b02ffba71f3d4e44",
      "bd82c7f9b62042348c106a3942b43648",
      "81da24c10d3c4147b911b6d93f5af96b",
      "2ce71aaab9a94e44af3a3e2df269e3a8",
      "2195cc4abc9647c8bb3e0751835bd7ec",
      "2850c48323e04d45a2c3e79edd15a761",
      "46758145253b4554aae0a5a2c2d77c5e",
      "aca1a5c3a84649788cc904d1700fe2e9",
      "f5794f9d63ca41ed985c19e15b53e92a",
      "11205e74acd34728affb19eab630347c",
      "09cf59d1b1fa4e3fb185ce89ea9a1e55",
      "ccb0e44a48ba41e5a3a2cbdb9c054d3d",
      "aa7e7659aa78444bafa6f8e9cc8a77f4",
      "655fb13e34f0400eb0f46a0933bd5513",
      "857b3e6b158243cd8114ce12e40e19a5"
     ]
    },
    "id": "NEf8wnRcMXWj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749296538292,
     "user_tz": -120,
     "elapsed": 18869,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "be8654d8-d816-437d-e064-7e66b5ca910e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31298aa403d44c0faf566b0c27f79dec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d2264aaf9854e5da736f50746c18bf3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5dc1c60b3a140f99d64071e32de923f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03c1ef724c414556a3c7f89f8170f9f2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "319564827f5846f787eab41b8c22141e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2195cc4abc9647c8bb3e0751835bd7ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# v'rification si j'ai du GPU\n",
    "from torch import cuda\n",
    "device = 'cuda'\n",
    "if cuda.is_available():\n",
    "    print(\"ok\")\n",
    "else: print('cpu')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jda66YFUMXlu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749296672612,
     "user_tz": -120,
     "elapsed": 43,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "4a8be6a2-a82b-4ccc-d6c8-4052701274fd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ok\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "base = pd.read_csv('amazone.csv', sep = \",\", low_memory=True, header=None, encoding='utf-8')\n",
    "base.rename(columns={0: \"grade\", 1: \"title\",2: \"comments\"}, inplace=True)\n",
    "base.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nz-yJ6qHMXzz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749297156812,
     "user_tz": -120,
     "elapsed": 1897,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "f208fc41-f86f-42b0-9f73-aaa89dd7df5f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   grade                                              title  \\\n",
       "0      2                                           Great CD   \n",
       "1      2  One of the best game music soundtracks - for a...   \n",
       "2      1                   Batteries died within a year ...   \n",
       "3      2              works fine, but Maha Energy is better   \n",
       "4      2                       Great for the non-audiophile   \n",
       "\n",
       "                                            comments  \n",
       "0  My lovely Pat has one of the GREAT voices of h...  \n",
       "1  Despite the fact that I have only played a sma...  \n",
       "2  I bought this charger in Jul 2003 and it worke...  \n",
       "3  Check out Maha Energy's website. Their Powerex...  \n",
       "4  Reviewed quite a bit of the combo players and ...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-3a48596b-3e4e-4c6b-81f5-ac5095be5b22\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Great CD</td>\n",
       "      <td>My lovely Pat has one of the GREAT voices of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "      <td>Despite the fact that I have only played a sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Batteries died within a year ...</td>\n",
       "      <td>I bought this charger in Jul 2003 and it worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>works fine, but Maha Energy is better</td>\n",
       "      <td>Check out Maha Energy's website. Their Powerex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the non-audiophile</td>\n",
       "      <td>Reviewed quite a bit of the combo players and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a48596b-3e4e-4c6b-81f5-ac5095be5b22')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3a48596b-3e4e-4c6b-81f5-ac5095be5b22 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3a48596b-3e4e-4c6b-81f5-ac5095be5b22');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-e190f33f-c586-4134-9f26-2f81f7b99ad7\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e190f33f-c586-4134-9f26-2f81f7b99ad7')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-e190f33f-c586-4134-9f26-2f81f7b99ad7 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "base"
      }
     },
     "metadata": {},
     "execution_count": 71
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "base.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cF7oCJzuMYBv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749297171348,
     "user_tz": -120,
     "elapsed": 39,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "f3ec22b3-6066-4b73-dc48-12e30f8a9013"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(400000, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Changement des labels en 1 ou 2 pour permettre une meilleure interprétation des modèles\n",
    "base['grade'] = base['grade'].replace(1, 0)\n",
    "base['grade'] = base['grade'].replace(2, 1)"
   ],
   "metadata": {
    "id": "UnX9U-WDMYOG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset : train / test\n",
    "\n",
    "base = base[['grade', 'comments']]\n",
    "base = base.copy()\n",
    "base.dropna(how='any', inplace=True)\n",
    "df_train = base.iloc[0:15000,:] # entrainement sur 15000 commentaires\n",
    "df_test = base.iloc[15000:20000,:] # test sur 5000 commentaires"
   ],
   "metadata": {
    "id": "Y7eXRUZ3MYcC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Entrainement et validation\n",
    "\n",
    "X = list(df_train[\"comments\"]) # liste de tous les commentaires\n",
    "y = list(df_train[\"grade\"]) # annotation binaire : 0 / 1\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512) ## tokenizer de RoBERTa"
   ],
   "metadata": {
    "id": "yF5RqmswMYoY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Test sur les commentaires que le réseau n'a jamais vu\n",
    "X_test = list(df_test[\"comments\"])\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)"
   ],
   "metadata": {
    "id": "aX3yA3RAMY0I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataloader : mise en forme des données :\n",
    "# je récupère l'id des input;\n",
    "#le masque d'attention pour compléter avec les 0 si un commentaire est petit en mettant un masque\n",
    "# token_type_ids ppur savoir si à quelle séquence appartient un mot\n",
    "# récupération de label\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ],
   "metadata": {
    "id": "m1xMttSSMY_t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cahargement des fonctions pour le calcul des métrics\n",
    "\n",
    "def compute_metrics(pred_arg):\n",
    "    pred, labels = pred_arg\n",
    "    pred = np.argmax(pred, axis=1) # classe majoritaire\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Definition des arguments d'entrainements\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    eval_strategy=\"steps\", # manière dévaluation du réseau (epochs est également possible)\n",
    "    eval_steps=500, # évaluations sur tous les 500 tokens\n",
    "    per_device_train_batch_size=8, # 8 commentaires\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,# le réseau verra que 2 fois le dataset\n",
    "    seed=0, # manière d'estimation du réseau\n",
    "    load_best_model_at_end=True # arr^t sur le meilleur modèle\n",
    "    )\n",
    "\n",
    "# Entrainement\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)] # après 3 étape et si la fonctionde cût n'augmente pas on arrête\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mDwThCuMZLN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749301812625,
     "user_tz": -120,
     "elapsed": 93,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "3d63f4ca-5796-457a-fed2-db34921e6701"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"  # désactive Weights et Biases pour éviter les messages d'erreurs\n",
    "from transformers import Trainer\n",
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "mwws4OPGMZVs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749304445155,
     "user_tz": -120,
     "elapsed": 2622189,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "ace11feb-7c8d-43fc-ed9d-b1ebed296888"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 43:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.508775</td>\n",
       "      <td>0.901667</td>\n",
       "      <td>0.875547</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.904685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.374303</td>\n",
       "      <td>0.906333</td>\n",
       "      <td>0.914676</td>\n",
       "      <td>0.895722</td>\n",
       "      <td>0.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.328900</td>\n",
       "      <td>0.382530</td>\n",
       "      <td>0.884333</td>\n",
       "      <td>0.832658</td>\n",
       "      <td>0.961230</td>\n",
       "      <td>0.892336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.295721</td>\n",
       "      <td>0.929333</td>\n",
       "      <td>0.941541</td>\n",
       "      <td>0.915107</td>\n",
       "      <td>0.928136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.303060</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.949861</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.930423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.181800</td>\n",
       "      <td>0.290742</td>\n",
       "      <td>0.932333</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>0.916444</td>\n",
       "      <td>0.931070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.24820156351725262, metrics={'train_runtime': 2621.2375, 'train_samples_per_second': 9.156, 'train_steps_per_second': 1.144, 'total_flos': 3662999223840000.0, 'train_loss': 0.24820156351725262, 'epoch': 2.0})"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test du dataset\n",
    "test_dataset = Dataset(X_test_tokenized)\n",
    "# Test\n",
    "test_trainer = Trainer(model)\n",
    "# prediction\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset) # prédiction des commenetaires jamais vus\n",
    "y_pred = np.argmax(raw_pred, axis=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "nDOrRGFudfAd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749304822933,
     "user_tz": -120,
     "elapsed": 148304,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "fe137dbf-c8a1-42a8-f2a0-43e6ef8d04ce"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# montre s'il reconnait les sentiments positifs et négatifs (0/1)\n",
    "y_pred"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_24G-2dndfeE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749304856325,
     "user_tz": -120,
     "elapsed": 15,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "2cc01846-db69-40b0-e3df-2dc1b724ee88"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test = list(df_test[\"grade\"])\n",
    "print('Accuracy :', accuracy_score(y_test, y_pred))\n",
    "print('F-measure :', f1_score(y_test, y_pred))\n",
    "print('Confusion matrix :', '\\n', confusion_matrix(y_test, y_pred))\n",
    "print('')\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJca5SqSdf1A",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749304893132,
     "user_tz": -120,
     "elapsed": 52,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "f13018e7-2ebd-493f-b80b-77e0828f5666"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy : 0.9366\n",
      "F-measure : 0.9384585517375267\n",
      "Confusion matrix : \n",
      " [[2266  127]\n",
      " [ 190 2417]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      2393\n",
      "           1       0.95      0.93      0.94      2607\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.94      0.94      0.94      5000\n",
      "weighted avg       0.94      0.94      0.94      5000\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Sur 2393 commentaires négatifs, le modèle à classer 92% correctements\n",
    "# Sur 2607 commentaires positifs, le modèle à classer 95% correctement"
   ],
   "metadata": {
    "id": "ZXw-w-x8syLp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "output_model_file = 'my_model.bin'\n",
    "output_vocab_file = './'\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file) # sauvegarde du vocabulaire également\n",
    "\n",
    "print('All files saved')\n",
    "print('This tutorial is done')"
   ],
   "metadata": {
    "id": "RJPF8G79df-r"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sauvegarde du modèle pour une autre fine tunning"
   ],
   "metadata": {
    "id": "tSx09PfquvOQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# sauvegarde du modèle et du vocabulaire en même temps\n",
    "model.save_pretrained(\"my_model\")\n",
    "tokenizer.save_pretrained(\"my_model\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aYv4Nb4wAsM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749306016832,
     "user_tz": -120,
     "elapsed": 20936,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "de527c6a-e003-4e3a-f3dc-92612d6de846"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('my_model/tokenizer_config.json',\n",
       " 'my_model/special_tokens_map.json',\n",
       " 'my_model/vocab.json',\n",
       " 'my_model/merges.txt',\n",
       " 'my_model/added_tokens.json')"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Rechargement pour une éventuelle utilisation\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"my_model\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"my_model\")\n",
    "model.eval()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DH88rgO1wBQ3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1749306208609,
     "user_tz": -120,
     "elapsed": 199,
     "user": {
      "displayName": "clement AMEGADJAKA",
      "userId": "15687380920917762763"
     }
    },
    "outputId": "aa058901-20be-4585-fb49-5b05a69489fa",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ]
  }
 ]
}